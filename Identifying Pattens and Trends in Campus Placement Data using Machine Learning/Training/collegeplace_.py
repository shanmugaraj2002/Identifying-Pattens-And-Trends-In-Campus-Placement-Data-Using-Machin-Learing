# -*- coding: utf-8 -*-
"""collegePlace .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UAW3GeoNvoZsIxv3iCiZejwxmgwyMWPR
"""

import numpy as np
import pandas as pd
import os 
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics 
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
from sklearn.metrics import accuracy_score

df=pd.read_csv('/content/collegePlace.csv')
df.head()

df.shape

sns.pairplot(df)

corr=df.corr()

ax = sns.heatmap(corr,vmin = -1,vmax = 1,annot=True)
bottom,top=ax.get_ylim()
ax.set_ylim(bottom+0.5,top - 0.5)
plt.show()
corr

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.displot(df['CGPA'],color ='r')

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.displot(df['PlacedOrNot'],color='r')

from seaborn.widgets import color_palette
plt.figure(figsize=(10,6),dpi=100)

color_palette = sns.color_palette("BuGn_r")
sns.set_palette(color_palette)

sns.countplot(x = "PlacedOrNot",data=df) 
              
plt.show

df.info()

df.isnull().sum()

df.describe()

df['Gender'].value_counts()

df['Stream'].value_counts()

df=df.replace(['Male'],[0])
df=df.replace(['Female'],[0])
df=df.replace(['Computer Science','Information Technology','Electronics And Communication','Mechanical','Electrical','Civil'],
              [0,1,2,3,4,5])
df

df.info()

def transformationplot(feature):
  plt.figure(figsize=(12,5))
  plt.subplot(1,2,1)
  sns.displot(feature)

transformationplot(np.log(df['Age']))

df=df.drop(["Hostel"],axis=1)
df

X = df.drop(columns = 'PlacedOrNot',axis=1)
Y = df['PlacedOrNot']

import joblib
joblib.dump(X,'Placement')

print(X)

print(Y)

scalar = StandardScaler()
scalar.fit(X)

standardized_data = scalar.transform(X)
print(standardized_data)

X = standardized_data
Y = df['PlacedOrNot']

"""# **Splitting the data**"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,stratify=Y,random_state=2)
print(X.shape,X_train.shape,X_test.shape)

"""# **Model 1**"""

classifier = svm.SVC(kernel='linear')
classifier.fit(X_train,Y_train)

#testing accurancy
X_test_prediction = classifier.predict(X_test)
Y_pred = accuracy_score(X_test_prediction,Y_test)
Y_pred

X_test

X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)
print('Accuracy score of the training data :',training_data_accuracy)

"""# **Model2 (KNN)**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.model_selection import cross_val_score

best_k={"Regular":0}
best_score={"Regular":0} 
for k in range(3, 50, 2):
 
## Using Regular training set
   knn_temp = KNeighborsClassifier(n_neighbors=k)
   knn_temp.fit(X_train, Y_train)
   knn_temp_pred = knn_temp.predict(X_test)
   score = metrics.accuracy_score(Y_test, knn_temp_pred)*100
   if score >=best_score["Regular"] and score<100:
     best_score["Regular"]=score
     best_k["Regular"] = k

print("---Results--nk: {}\nScore: {}".format(best_k, best_score)) 
knn=KNeighborsClassifier(n_neighbors=best_k["Regular"])
knn.fit(X_train,Y_train)
knn_pred=knn.predict(X_test)
testd=accuracy_score(knn_pred, Y_test)

knn_pred

"""# **Model3(ANN)**"""

X_train.shape

Y_train.shape

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from tensorflow.keras import layers

classifier=Sequential()

classifier.add(keras.layers.Dense (6, activation ='relu', input_dim= 6)) 
classifier.add(keras.layers.Dropout (0.50))

classifier.add(keras.layers.Dense (6, activation = 'relu'))
classifier.add(keras.layers.Dropout (0.50))

classifier.add(keras.layers.Dense(1, activation = 'sigmoid'))

#Compiling the model

loss_1 = tf. keras.losses.BinaryCrossentropy()

classifier.compile(optimizer= "Adam", loss=loss_1, metrics = ['accuracy'])

classifier.fit(X_train,Y_train,batch_size=20,epochs=100)

pred = classifier.predict(X_test)
pred = (pred > 0.5)
pred

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test,pred)
cm

"""# **saving and downloading**"""

import pickle
pickle.dump(knn,open('Placement.pkl','wb'))
model = pickle.load(open('Placement.pkl','rb'))

input_data = [[22,0,2,1,8,1]]
prediction=knn.predict(input_data)
print(prediction)

if(prediction==0):
  print('not placed')
else:
  print('placed')